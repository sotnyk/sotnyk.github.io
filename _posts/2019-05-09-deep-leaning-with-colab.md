---
id: 1826
title: 'Deep Leaning with Colab'
date: '2019-05-09T14:34:40+00:00'
author: serge
layout: post
guid: 'https://sotnyk.ga/?p=1826'
permalink: /2019/05/09/deep-leaning-with-colab/
---

Как известно, Гугл дает возможность бесплатно использовать Jupyter Notebook, работающие на их серверах с аппаратными ускорителями (я имею в виду [их Colab](https://colab.research.google.com/)). Там есть серьезные ограничения, прежде всего те, что нужно следить за сессиями и возобновлять их, пока машина не канула в небытие вместе со всеми изменениями, данными и уже просчитанными переменными. Но я нашел у себя сценарий, когда этот инструмент будет вполне полезным (не считая обучения).

Поехал в Киев с одним лэптопом, карточка у которого практически не приспособлена для глубокого обучения. А обучать временами нужно. И приспособился делать так:

Создаю ноутбук, в котором выполняю подготовку данных, конструирование модели. Закидываю все это на гитхаб (или любое другое место, которое доступно Colab). И дальше выполняю серию экспериментов с разными параметрами у Гугла в облаке. При этом получается считать быстрее, чем на моем лэптопе (хотя и его обычно нагружаю параллельно). Получив удачный набор гиперпараметров, я уже на ночь оставляю модель учиться на лэптопе.

Какие моменты важны:

- Стараюсь, чтобы код ноутбука был одним и тем же. Утомляет при открытии каждой сессии вносить одинаковые правки, подгружать файлы. Для этого код пишется так, чтобы загружать данные прямо из интернета (с помощью пакета wget, например), если они не обнаружены в подпапке /data (которая у меня обычно стоит в .gitignore). А еще – если работаем в Colab, то подгружаем определенные пакеты. Примерно так:

```
<pre class="wp-block-preformatted">try:
    import google.colab
    IN_COLAB = True
except:
    IN_COLAB = False

if IN_COLAB:
    !pip install wget conllu
```

Конечно, можно каждый раз их прогружать и локально, но зачем?

- Еще не забываем при инициализации выбрать окружение с аппаратным ускорением. Иначе все будет работать только за счет процессора, т.е., медлено. Доступно 2 типа ускорения – TPU и GPU. В моих текущих экспериментах быстрее себя показал GPU. Помимо этого, был приятный бонус, что на виртуальных машинах с этим типом ускорителя больше дается памяти (оперативной и дисковой). Наверняка, это зависит от конкретной загрузки и количества аппаратных средств, так что в будущем все может измениться. Так что если не хватает именно памяти – попробуйте сменить тип окружения, может поможет.