---
id: 1226
title: 'Случаи из практики. Случай 1. Настраиваем PLINQ.'
date: '2012-09-16T18:28:59+00:00'
author: serge
layout: post
guid: 'http://sotnyk.com/?p=1226'
permalink: /2012/09/16/sluchai-iz-praktiki-sluchay-1-nastraivaem-plinq/
---

![](http://localhost/wp-content/uploads/2012/09/Sluchai-is-praktiki-198x300.jpg "Sluchai-is-praktiki")Дано: есть утилита, которая обрабатывает данные от многих магазинов. Обработка идет на достаточно мощном компьютере, имеющем 8 ядер, поэтому для ускорения она распараллеливается. Каждый магазин обрабатывается в своем потоке. Использование PLINQ, делает такое распараллеливание делом достаточно нехитрым.

Вот исходный код:

\[csharp\]  
static void UpdateDatabase(FileInfo\[\] xmlFeeds)  
{  
 xmlFeeds.AsParallel().ForAll(xml =&gt;  
 {  
 …  
\[/csharp\]

Дальше идет собственно код, который обрабатывает информацию от каждого магазина отдельно. В чем загвоздка? А она в том, что все магазины очень разные по размеру. Одни присылают файл меньше мегабайта, другие по 600 мегабайт. По умолчанию же PLINQ для тех, кто реализует IList, реализует такую стратегию разбиения на порции:

> Делим всю работу на N порций, которые затем подаем каждому из воркеров (количество воркеров по умолчанию зависит от количества вычислительных ядер в системе).

Такая стратегия дает возможность быстро разделить порции работы между воркерами, но равномерной эта загрузка получится только тогда, когда эти порции более-менее равноценны. В нашем же случае это не так. И на практике получали ситуацию, когда один воркер большую часть времени работал в гордом одиночестве. Т.е., реальная прибавка в производительности была меньше, чем в 2 раза.

Решение проблемы состоит в изменении стратегии. Теперь она будет такой:

> Прежде всего, необходимо раздать самые тяжелые порции работы. По мере освобождения воркеров им необходимо брать самую тяжелую порцию, которая еще осталась.

Для того, чтобы узнать, какая порция самая тяжелая, нам необходимо разобрать XML файл, поэтому напрямую мы не будем пользоваться этим критерием, а воспользуемся сильно коррелированной с ним характеристикой – размером обрабатываемого файла. А для того, чтобы явно указать PLINQ, что порции необходимо подавать воркерам динамически, по мере их освобождения, мы используем класс Partitioner, в конструкторе которого указываем параметр loadBalance=true. Получаем следующий код:

\[csharp\]  
static void UpdateDatabase(FileInfo\[\] xmlFeeds)  
{  
 // Sort by file size from big to small  
 var sortedXmlFeeds = xmlFeeds  
 .OrderByDescending(f =&gt; f.Length).ToList();  
 // And use sectioning by blocks to right work balancing  
 Partitioner.Create(sortedXmlFeeds, true).AsParallel()  
 .ForAll(xml =&gt;  
 {  
 …  
\[/csharp\]

Такая модификация кода на практике дала прибавку в скорости работы более, чем в 2 раза по сравнению с предыдущей версией (зависит от используемых данных).

Можно и дальше ускорять – ведь в самом конце работы все равно возникает момент, когда работают не все воркеры. Поэтому можно дальше делить порции работы, обрабатывая каждый магазин параллельно. Но это уже не даст такой большой прибавки, и потребует более сильного изменения кода.

Желающих почитать про тонкую настройку параллельной работы в C#, приглашаю почитать [эту статью](http://rsdn.ru/article/dotnet/Threading_In_C_Sharp_Part_3.xml?print) (перевод [руководства Джозефа Албахари](http://www.albahari.com/threading/)). Переводчик – [Тепляков Сергей, блог](http://sergeyteplyakov.blogspot.com/) которого тоже достаточно интересен и внесен в мои закладки.