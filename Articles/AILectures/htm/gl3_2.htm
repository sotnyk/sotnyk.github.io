<html>

<head>
	<title>Перцептроны</title>
	<link rel=stylesheet href="..\css\lectures.css" type="text/css">
	<meta charset="utf-8"/>
</head>

<body bgcolor="#F2F2F2">

<center>
<h3><a NAME="_Toc429431267">Перцептроны</a></h3>
</center>

<p>Пока о проблеме обучения распознаванию образов удавалось говорить в общих чертах, не выделяя конкретные методы 
или алгоритмы, не возникало и трудностей, появляющихся всяких раз, когда приходится разбираться в огромном 
множестве конкретных примеров, характеризующиеся общими подходами к решению проблемы ОРО. Коварство самой 
проблемы состоит в том, что на первый взгляд все методы и алгоритмы кажутся совершенно различными и, что самое 
неприятное, часто никакой из них не годится для решения той задачи, которую крайне необходимо срочно решить. И тогда 
появляется желание выдумать новый алгоритм, который, может быть, достигнет цели. Очевидно, именно это привело к 
возникновению огромного множества алгоритмов, в котором не так-то легко разобраться.</p>

<p>Одним из методов решения задач обучения распознаванию образов основан на моделировании гипотетического 
механизма человеческого мозга. Структура модели заранее постулируется. При таком подходе уровень биологических 
знаний или гипотез о биологических механизмах является исходной предпосылкой, на которой базируются модели этих 
механизмов. Примером такого направления в теории и практике проблемы ОРО является класс устройств, называемых 
перцептронами. Нужно отметить, что перцептроны на заре своего возникновения рассматривались только как 
эвристические модели механизма мозга. Впоследствии они стали основополагающей схемой в построении 
кусочно-линейных моделей, обучающихся распознаванию образов.</p>


<p class="picture"><a NAME="_Ref397682583">Рис. 1</a></p>


<p><img SRC="..\img\image71.gif" WIDTH="599" HEIGHT="449"></p>


<p>В наиболее простом виде перцептрон (Рис. 1) состоит из совокупности чувствительных (сенсорных) элементов 
(S-элементов), на которые поступают входные сигналы. S-элементы случайным образом связаны с совокупностью 
ассоциативных элементов (А-элементов), выход которых отличается от нуля только тогда, когда возбуждено достаточно
большое число S-элементов, воздействующих на один А-элемент. А-элементы соединены с реагирующими элементами 
(R-элементами) связями, коэффициенты усиления (v) которых переменны и изменяются в процессе обучения. Взвешенные 
комбинации выходов R-элементов составляют реакцию системы, которая указывает на принадлежность распознаваемого 
объекта определенному образу. Если распознаются только два образа, то в перцептроне устанавливается только один 
R-элемент, который обладает двумя реакциями — положительной и отрицательной. Если образов больше двух, то для 
каждого образа устанавливают свой R-элемент, а выход каждого такого элемента представляет линейную комбинацию 
выходов A-элементов:</p>

<p><img SRC="..\img\image72.gif" WIDTH="150" HEIGHT="56" BORDER="0">, (ф. 1)</p>

<p>где R<sub>j</sub> — реакция j-го R-элемента; x<sub>i</sub> — реакция i-го A-элемента; v<sub>ij</sub> — вес связи от i-го 
A-элемента к j-му R элементу; <font FACE="Symbol">Q</font><sub>j</sub> — порог j-го R-элемента. </p>

<p>Аналогично записывается уравнение i-го A-элемента: </p>


<p><img SRC="..\img\image73.gif" WIDTH="126" HEIGHT="56">, (ф. 2)</p>


<p>Здесь сигнал y<sub>k</sub> может быть непрерывным, но чаще всего он принимает только два значения: 0 или 1.
Сигналы от S-элементов подаются на входы А-элементов с постоянными весами равными единице, но каждый А-элемент
связан только с группой случайно выбранных S-элементов. Предположим, что требуется обучить перцептрон различать два 
образа V<sub>1</sub> и V<sub>2</sub>. Будем считать, что в перцептроне существует два R-элемента, один из которых
предназначен образу V<sub>1</sub>, а другой — образу V<sub>2</sub>. Перцептрон будет обучен правильно, если выход 
R<sub>1</sub> превышает R<sub>2</sub>, когда распознаваемый объект принадлежит образу V<sub>1</sub>, и наоборот. 
Разделение объектов на два образа можно провести и с помощью только одного R-элемента. Тогда объекту образа 
V<sub>1</sub> должна соответствовать положительная реакция R-элемента, а объектам образа V<sub>2</sub> — 
отрицательная.</p>

<p>Перцептрон обучается путем предъявления обучающей последовательности изображений объектов, принадлежащих 
образам V<sub>1</sub> и V<sub>2</sub>. В процессе обучения изменяются веса v<sub>i</sub> А-элементов. В частности, 
если применяется система подкрепления с коррекцией ошибок, прежде всего учитывается правильность решения, 
принимаемого перцептроном. Если решение  правильно, то веса связей всех сработавших А-элементов, ведущих к 
R-элементу, выдавшему правильное решение, увеличиваются, а веса несработавших А-элементов остаются неизменными. 
Можно оставлять неизменными веса сработавших А-элементов, но уменьшать веса несработавших. В некоторых случаях 
веса сработавших связей увеличивают, а несработавших — уменьшают. После процесса обучения перцептрон сам, без 
учителя, начинает классифицировать новые объекты.</p>

<p>Если перцептрон действует по описанной схеме и в нем допускаются лишь связи, идущие от бинарных S-элементов к 
A-элементам и от A-элементов к единственному R-элементу, то такой перцептрон принято называть элементарным 
<font FACE="Symbol">a</font>-перцептроном. Обычно классификация C(W) задается учителем. Перцептрон должен 
выработать в процессе обучения классификацию, задуманную учителем.</p>

<p>О перцептронах было сформулировано и доказано несколько основополагающих теорем, две из которых, определяющие 
основные свойства перцептрона, приведены ниже.</p>


<p>Теорема 1. Класс элементарных <font FACE="Symbol">a</font>-перцептронов, для которых существует решение для 
любой задуманной классификации, не является пустым.</p>

<p>Эта теорема утверждает, что для любой классификации обучающей последовательности можно подобрать такой набор 
(из бесконечного набора) А-элементов, в котором будет осуществлено задуманное разделение обучающей 
последовательности при помощи линейного решающего правила ).</p>

<p>Теорема 2. Если для некоторой классификации C(W) решение существует, то в процессе обучения 
<font FACE="Symbol">a</font> -перцептрона с коррекцией ошибок, начинающегося с произвольного исходного состояния, 
это решение будет достигнуто в течение конечного промежутка времени.</p>

<p>Смысл этой теоремы состоит в том, что если относительно задуманной классификации можно найти набор А-элементов, 
в котором существует решение, то в рамках этого набора оно будет достигнуто в конечный промежуток времени.</p>

<p>Обычно обсуждают свойства бесконечного перцептрона, т. е. перцептрона с бесконечным числом А-элементов со 
всевозможными связями с S-элементами (полный набор A-элементов). В таких перцептронах решение всегда существует, 
а раз оно существует, то оно и достижимо в <font FACE="Symbol">a</font> -перцептронах с коррекцией ошибок.</p>

<p>Очень интересную область исследований представляют собой многослойные перцептроны и перцептроны с 
перекрестными связями, но теория этих систем практически еще не разработана.</p>

</body>
</html>
