<html>
<head>
	<title>Нейронные сети</title>
	<link rel=stylesheet href="..\css\lectures.css" type="text/css">
	<meta charset="utf-8"/>
</head>

<body bgcolor="#F2F2F2">

<center>
<h3><a NAME="_Toc429431268">Нейронные сети</a></h3>

<p>&nbsp;
<br><br>
<a name="_Toc429431269">
<b><i>История исследований в области нейронных сетей</i></b>
</a>
</p>
</center>

<p>Возвратимся немного назад, и рассмотрим историю исследований нейронных сетей.</p>

<p>В истории исследований в области нейронных сетей, как и в истории любой другой науки, были свои успехи и неудачи. 
Кроме того, здесь постоянно сказывается психологический фактор, проявляющийся в неспособности человека
описать словами то, как он думает.</p>

<p>Способность нейронной сети к обучению впервые исследована Дж. Маккалоком и У. Питтом. В 1943 году вышла их 
работа &quot;Логическое исчисление идей, относящихся к нервной деятельности&quot;, в которой была построена модель 
нейрона, и сформулированы принципы построения искусственных нейронных сетей.</p>

<p>Крупный толчок развитию нейрокибернетики дал американский нейрофизиолог Френк Розенблатт, предложивший в
1962 году свою модель нейронной сети — персептрон. Воспринятый первоначально с большим энтузиазмом, он вскоре 
подвергся интенсивным нападкам со стороны крупных научных авторитетов. И хотя подробный анализ их аргументов
показывает, что они оспаривали не совсем тот персептрон, который предлагал Розенблатт, крупные исследования по 
нейронным сетям были свернуты почти на 10 лет.</p>

<p>Несмотря на это в 70-е годы было предложено много интересных разработок, таких, например, как когнитрон, 
способный хорошо распознавать достаточно сложные образы независимо от поворота и изменения масштаба
изображения.</p>

<p>В 1982 году американский биофизик Дж. Хопфилд предложил оригинальную модель нейронной сети, названную его 
именем. В последующие несколько лет было найдено множество эффективных алгоритмов: сеть встречного потока,
двунаправленная ассоциативная память и др.</p>

<p>В киевском институте кибернетики с 70-х годов ведутся работы над стохастическими нейронными сетями.</p>

<center>
<p>&nbsp;
<br><br>
<a name="_Toc429431270">
<b><i>Модель нейронной сети с обратным распространением ошибки (back propagation)</i></b>
</a>
</p>
</center>

<p>В 1986 году Дж. Хинтон и его коллеги опубликовали статью с описанием модели нейронной сети и алгоритмом ее 
обучения, что дало новый толчок исследованиям в области искусственных нейронных сетей.</p>

<p>Нейронная сеть состоит из множества одинаковых элементов — нейронов, поэтому начнем с них рассмотрение работы 
искусственной нейронной сети.</p>

<p>Биологический нейрон моделируется как устройство, имеющее несколько входов (дендриты), и один выход (аксон). 
Каждому входу ставится в соответствие некоторый весовой коэффициент (w), характеризующий пропускную способность 
канала и оценивающий степень влияния сигнала с этого входа на сигнал на выходе. В зависимости от конкретной 
реализации, обрабатываемые нейроном сигналы могут быть аналоговыми или цифровыми (1 или 0). В теле нейрона 
происходит взвешенное суммирование входных возбуждений, и далее это значение является аргументом активационной
функции нейрона, один из возможных вариантов которой представлен на Рис. 1.</p>

<p ALIGN="CENTER"><img SRC="..\img\image55.gif" WIDTH="600" HEIGHT="450"></p>
<p ALIGN="CENTER" class="picture"><a NAME="_Ref397692849">Рис. 1</a> Искусственный нейрон</p>

<p>Будучи соединенными определенным образом, нейроны образуют нейронную сеть. Работа сети разделяется на обучение 
и адаптацию. Под обучением понимается процесс адаптации сети к предъявляемым эталонным образцам путем 
модификации (в соответствии с тем или иным алгоритмом) весовых коэффициентов связей между нейронами. Заметим, 
что этот процесс является результатом алгоритма функционирования сети, а не предварительно заложенных в нее знаний
человека, как это часто бывает в системах искусственного интеллекта.</p>

<p>Среди различных структур нейронных сетей (НС) одной из наиболее известных является многослойная структура, в 
которой каждый нейрон произвольного слоя связан со всеми аксонами нейронов предыдущего слоя или, в случае первого
слоя, со всеми входами НС. Такие НС называются полносвязными. Когда в сети только один слой, алгоритм ее обучения с 
учителем довольно очевиден, так как правильные выходные состояния нейронов единственного слоя заведомо известны, и
подстройка синаптических связей идет в направлении, минимизирующем ошибку на выходе сети. По этому принципу 
строится, например, алгоритм обучения однослойного перцептрона. В многослойных же сетях оптимальные выходные
значения нейронов всех слоев, кроме последнего, как правило, не известны, и двух или более слойный перцептрон уже 
невозможно обучить, руководствуясь только величинами ошибок на выходах НС. Один из вариантов решения этой
проблемы – разработка наборов выходных сигналов, соответствующих входным, для каждого слоя НС, что, конечно, 
является очень трудоемкой операцией и не всегда осуществимо. Второй вариант – динамическая подстройка весовых
коэффициентов синапсов, в ходе которой выбираются, как правило, наиболее слабые связи и изменяются на малую 
величину в ту или иную сторону, а сохраняются только те изменения, которые повлекли уменьшение ошибки на выходе
всей сети. Очевидно, что данный метод &quot;тыка&quot;, несмотря на свою кажущуюся простоту, требует громоздких 
рутинных вычислений. И, наконец, третий, более приемлемый вариант – распространение сигналов ошибки от выходов НС к
ее входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы. Этот алгоритм 
обучения НС получил название процедуры обратного распространения. Именно он будет рассмотрен в дальнейшем.</p>

<p>Согласно методу наименьших квадратов, минимизируемой целевой функцией ошибки НС является величина:</p>

<p><img SRC="..\img\image56.gif" WIDTH="220" HEIGHT="58"> (1)</p>

<p>где <img SRC="..\img\image57.gif" WIDTH="38" HEIGHT="33"> – реальное выходное состояние нейрона j выходного слоя 
N нейронной сети при подаче на ее входы p-го образа;  d<sub>jp</sub> – идеальное (желаемое) выходное состояние этого
нейрона.</p>

<p>Суммирование ведется по всем нейронам выходного слоя и по всем обрабатываемым сетью образам. Минимизация 
ведется методом градиентного спуска, что означает подстройку весовых коэффициентов следующим образом:</p>

<p><img SRC="..\img\image58.gif" WIDTH="141" HEIGHT="58"> (2)</p>

<p>Здесь w<sub>ij</sub> – весовой коэффициент синаптической связи, соединяющей i-ый нейрон слоя n-1 с j-ым нейроном 
слоя n, <font FACE="Symbol">h</font> – коэффициент скорости обучения, 0&lt;<font FACE="Symbol">h</font> &lt;1.</p>

<p>Как показано в [2],</p>
<p><img SRC="..\img\image59.gif" WIDTH="180" HEIGHT="61"> (3)</p>

<p>Здесь под y<sub>j</sub>, как и раньше, подразумевается выход нейрона j, а под s<sub>j</sub> – взвешенная сумма его 
входных сигналов, то есть аргумент активационной функции. Так как множитель dy<sub>j</sub>/ds<sub>j</sub> является 
производной этой функции по ее аргументу, из этого следует, что производная активационной функция должна быть
определена на всей оси абсцисс. В связи с этим функция единичного скачка и прочие активационные функции с 
неоднородностями не подходят для рассматриваемых НС. В них применяются такие гладкие функции, как гиперболический 
тангенс или классический сигмоид с экспонентой. В случае гиперболического тангенса</p>


<p><img SRC="..\img\image60.gif" WIDTH="91" HEIGHT="51"> (4)</p>

<p>Третий множитель <font FACE="Symbol">¶</font> s<sub>j</sub>/<font FACE="Symbol">¶</font> w<sub>ij</sub>, очевидно, 
равен выходу нейрона предыдущего слоя y<sub>i</sub><sup>(n-1)</sup>.</p>

<p>Что касается первого множителя в (3), он легко раскладывается следующим образом[2]:</p>

<p><img SRC="..\img\image61.gif" WIDTH="360" HEIGHT="60"> (5)</p>

<p>Здесь суммирование по k выполняется среди нейронов слоя n+1.</p>

<p>Введя новую переменную</p>

<p><img SRC="..\img\image62.gif" WIDTH="130" HEIGHT="61"> (6)</p>

<p>мы получим рекурсивную формулу для расчетов величин <font FACE="Symbol">d</font> <sub>j</sub><sup>(n)</sup> слоя 
n из величин  <font FACE="Symbol">d</font> <sub>k</sub><sup>(n+1)</sup> более старшего слоя n+1.</p>

<p><img SRC="..\img\image63.gif" WIDTH="238" HEIGHT="61"> (7)</p>

<p>Для выходного же слоя</p>

<p><img SRC="..\img\image64.gif" WIDTH="186" HEIGHT="58"> (8)</p>

<p>Теперь мы можем записать (2) в раскрытом виде:</p>

<p><img SRC="..\img\image65.gif" WIDTH="188" HEIGHT="33"> (9)</p>

<p>Иногда для придания процессу коррекции весов некоторой инерционности, сглаживающей резкие скачки при 
перемещении по поверхности целевой функции, (9) дополняется значением изменения веса на предыдущей итерации</p>

<p><img SRC="..\img\image66.gif" WIDTH="428" HEIGHT="33"> (10)</p>

<p>где <font FACE="Symbol">m</font> – коэффициент инерционности, t – номер текущей итерации.</p>

<p>Таким образом, полный алгоритм обучения НС с помощью процедуры обратного распространения строится так:</p>

<p>1. Подать на входы сети один из возможных образов и в режиме обычного функционирования НС, когда сигналы
распространяются от входов к выходам, рассчитать значения последних. Напомним, что</p>

<p><img SRC="..\img\image67.gif" WIDTH="165" HEIGHT="58"> (11)</p>

<p>где M – число нейронов в слое n-1 с учетом нейрона с постоянным выходным состоянием +1, задающего смещение; 
y<sub>i</sub><sup>(n-1)</sup>=x<sub>ij</sub><sup>(n)</sup> – i-ый вход нейрона j слоя n.</p>

<p>y<sub>j</sub><sup>(n)</sup> = f(s<sub>j</sub><sup>(n)</sup>), где f() – сигмоид (12)</p>

<p>y<sub>q</sub><sup>(0)</sup>=I<sub>q</sub>, (13)</p>

<p>где I<sub>q</sub> – q-ая компонента вектора входного образа.</p>

<p>2. Рассчитать <font FACE="Symbol">d</font> <sup>(N)</sup> для выходного слоя по формуле (8).</p>

<p>Рассчитать по формуле (9) или (10) изменения весов <font FACE="Symbol">D</font> w<sup>(N)</sup> слоя N.</p>

<p>3. Рассчитать по формулам (7) и (9) (или (7) и (10)) соответственно <font FACE="Symbol">d</font> <sup>(n)</sup> и 
<font FACE="Symbol">D</font> w<sup>(n)</sup> для всех остальных слоев, n=N-1,...1.</p>

<p>4. Скорректировать все веса в НС</p>

<p><img SRC="..\img\image68.gif" WIDTH="248" HEIGHT="33"> (14)</p>

<p>5. Если ошибка сети существенна, перейти на шаг 1. В противном случае – конец.</p>

<p align="center"><img SRC="..\img\image69.gif" WIDTH="640" HEIGHT="640" HSPACE="11"> </p>
<p ALIGN="CENTER" class="picture"><a NAME="_Ref397692849">Рис. 2.</a></p>




<p>Сети на шаге 1 попеременно в случайном порядке предъявляются все тренировочные образы, чтобы сеть, образно 
говоря, не забывала одни по мере запоминания других. Алгоритм иллюстрируется Рис. 2.</p>

<p>Из выражения (9) следует, что когда выходное значение y<sub>i</sub><sup>(n-1)</sup> стремится к нулю, эффективность 
обучения заметно снижается. При двоичных входных векторах в среднем половина весовых коэффициентов не будет
корректироваться[3], поэтому область возможных значений выходов нейронов [0,1] желательно сдвинуть в пределы 
[-0.5,+0.5], что достигается простыми модификациями логистических функций. Например, сигмоид с экспонентой 
преобразуется к виду</p>

<p><img SRC="..\img\image70.gif" WIDTH="185" HEIGHT="51"> (15)</p>

<p>Теперь коснемся вопроса емкости НС, то есть числа образов, предъявляемых на ее входы, которые она способна 
научиться распознавать. Для сетей с числом слоев больше двух, он остается открытым. Как показано в [4], для НС с двумя 
слоями, то есть выходным и одним скрытым слоем, детерминистская емкость сети C<sub>d</sub> оценивается так:</p>

<p>N<sub>w</sub>/N<sub>y</sub>&lt;C<sub>d</sub>&lt;N<sub>w</sub>/N<sub>y<font FACE="Symbol">?</font> 
</sub>log(N<sub>w</sub>/N<sub>y</sub>) (16)</p>

<p>где N<sub>w</sub> – число подстраиваемых весов, N<sub>y</sub> – число нейронов в выходном слое.</p>

<p>Следует отметить, что данное выражение получено с учетом некоторых ограничений. Во-первых, число входов 
N<sub>x</sub> и нейронов в скрытом слое N<sub>h</sub> должно удовлетворять неравенству 
N<sub>x</sub>+N<sub>h</sub>&gt;N<sub>y</sub>. Во-вторых, N<sub>w</sub>/N<sub>y</sub>&gt;1000. Однако 
вышеприведенная оценка выполнялась для сетей с активационными функциями нейронов в виде порога, а емкость сетей
с гладкими активационными функциями, например – (15), обычно больше. Кроме того, фигурирующее в названии емкости 
прилагательное &quot;детерминистский&quot; означает, что полученная оценка емкости подходит абсолютно для всех
возможных входных образов, которые могут быть представлены N<sub>x</sub> входами. В действительности
распределение входных образов, как правило, обладает некоторой регулярностью, что позволяет НС проводить обобщение 
и, таким образом, увеличивать реальную емкость. Так как распределение образов, в общем случае, заранее не известно, 
мы можем говорить о такой емкости только предположительно, но обычно она раза в два превышает емкость 
детерминистскую.</p>

<p>В продолжение разговора о емкости НС логично затронуть вопрос о требуемой мощности выходного слоя сети, 
выполняющего окончательную классификацию образов. Дело в том, что для разделения множества входных образов, 
например, по двум классам достаточно всего одного выхода. При этом каждый логический уровень – &quot;1&quot; и
&quot;0&quot; – будет обозначать отдельный класс. На двух выходах можно закодировать уже 4 класса и так далее. Однако 
результаты работы сети, организованной таким образом, можно сказать – &quot;под завязку&quot;, – не очень надежны. 
Для повышения достоверности классификации желательно ввести избыточность путем выделения каждому классу одного 
нейрона в выходном слое или, что еще лучше, нескольких, каждый из которых обучается определять принадлежность 
образа к классу со своей степенью достоверности, например: высокой, средней и низкой. Такие НС позволяют проводить 
классификацию входных образов, объединенных в нечеткие (размытые или пересекающиеся) множества. Это свойство
приближает подобные НС к условиям реальной жизни.</p>

<p>Рассматриваемая НС имеет несколько &quot;узких мест&quot;. Во-первых, в процессе обучения может возникнуть 
ситуация, когда большие положительные или отрицательные значения весовых коэффициентов сместят рабочую точку на
сигмоидах многих нейронов в область насыщения. Малые величины производной от логистической функции приведут в 
соответствие с (7) и (8) к остановке обучения, что парализует НС. Во-вторых, применение метода градиентного спуска не
гарантирует, что будет найден глобальный, а не локальный минимум целевой функции. Эта проблема связана еще с одной, 
а именно – с выбором величины скорости обучения. Доказательство сходимости обучения в процессе обратного 
распространения основано на производных, то есть приращения весов и, следовательно, скорость обучения должны
быть бесконечно малыми, однако в этом случае обучение будет происходить неприемлемо медленно. С другой стороны, 
слишком большие коррекции весов могут привести к постоянной неустойчивости процесса обучения. Поэтому в качестве 
<font FACE="Symbol">h</font> обычно выбирается число меньше 1, но не очень маленькое, например, 0.1, и оно, вообще 
говоря, может постепенно уменьшаться в процессе обучения. Кроме того, для исключения случайных попаданий в 
локальные минимумы иногда, после того как значения весовых коэффициентов застабилизируются, 
<font FACE="Symbol">h</font> кратковременно сильно увеличивают, чтобы начать градиентный спуск из новой точки. Если
повторение этой процедуры несколько раз приведет алгоритм в одно и то же состояние НС, можно более или менее 
уверенно сказать, что найден глобальный максимум, а не какой-то другой.</p>

<p>Существует и иной метод исключения локальных минимумов, а заодно и паралича НС, заключающийся в применении 
стохастических НС, но о них лучше поговорить отдельно.</p>

</body>
</html>
